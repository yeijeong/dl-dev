{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링할 url 생성하는 함수 만들기(검색어, 크롤링 시작 페이지, 크롤링 종료 페이지)\n",
    "def makeUrl(search, page, maxpage_t, sort, s_date, e_date, s_from, e_to):\n",
    "    urls = []\n",
    "    if page == maxpage_t:       # 최대페이지 1일 경우\n",
    "        url = \"https://search.naver.com/search.naver?where=news&query=\" + search + \"&sort=\"+sort+\"&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page)\n",
    "        urls.append(url)\n",
    "    else:\n",
    "        while page <= maxpage_t :\n",
    "            url = \"https://search.naver.com/search.naver?where=news&query=\" + search + \"&sort=\"+sort+\"&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page)\n",
    "            urls.append(url)\n",
    "            page += 10\n",
    "    return urls    \n",
    "\n",
    "# html에서 원하는 속성 추출하는 함수 만들기 (기사, 추출하려는 속성값)\n",
    "def news_attrs_crawler(articles,attrs):\n",
    "    attrs_content=[]\n",
    "    for i in articles:\n",
    "        attrs_content.append(i.attrs[attrs])\n",
    "    return attrs_content\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'}\n",
    "\n",
    "#html생성해서 기사크롤링하는 함수 만들기(url): 링크를 반환\n",
    "def articles_crawler(url):\n",
    "    #html 불러오기\n",
    "    original_html = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "    html = BeautifulSoup(original_html.text, \"html.parser\")\n",
    "\n",
    "    url_naver = html.select(\"div.group_news > ul.list_news > li div.news_area > div.news_info > div.info_group > a.info\")\n",
    "    url = news_attrs_crawler(url_naver,'href')\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_all(search, page, maxpage_t, sort, s_date, e_date, s_from, e_to) :\n",
    "    # naver url 생성\n",
    "    urls = makeUrl(search, page, maxpage_t, sort, s_date, e_date, s_from, e_to)\n",
    "\n",
    "    #뉴스 크롤러 실행\n",
    "    news_titles = []\n",
    "    news_url =[]\n",
    "    news_contents =[]\n",
    "    news_dates = []\n",
    "\n",
    "    while page <= maxpage_t :\n",
    "        url_origin = \"https://search.naver.com/search.naver?where=news&query=\" + search + \"&sort=\"+sort+\"&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page)\n",
    "        url = articles_crawler(url_origin)\n",
    "        news_url .append(url)\n",
    "        page += 10\n",
    "\n",
    "    #제목, 링크, 내용 1차원 리스트로 꺼내는 함수 생성\n",
    "    def makeList(newlist, content):\n",
    "        for i in content:\n",
    "            for j in i:\n",
    "                newlist.append(j)\n",
    "        return newlist\n",
    "\n",
    "    #제목, 링크, 내용 담을 리스트 생성\n",
    "    news_url_1 = []\n",
    "\n",
    "    #1차원 리스트로 만들기(내용 제외)\n",
    "    makeList(news_url_1,news_url)\n",
    "\n",
    "    #NAVER 뉴스만 남기기\n",
    "    final_urls = []\n",
    "    for i in range(len(news_url_1)):\n",
    "        if \"news.naver.com\" in news_url_1[i]:\n",
    "            final_urls.append(news_url_1[i])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for i in final_urls:\n",
    "        #각 기사 html get하기\n",
    "        headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'}\n",
    "        news = requests.get(i, headers=headers, verify=False)\n",
    "        news_html = BeautifulSoup(news.text,\"html.parser\")\n",
    "\n",
    "        # 뉴스 제목 가져오기\n",
    "        title = news_html.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "        if title == None:\n",
    "            title = news_html.select_one(\"#content > div.end_ct > div > h2\")\n",
    "        \n",
    "        # 뉴스 본문 가져오기\n",
    "        content = news_html.select(\"div#dic_area\")\n",
    "        if content == []:\n",
    "            content = news_html.select(\"#articeBody\")\n",
    "            \n",
    "        # 기사 텍스트만 가져오기\n",
    "        # list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        pattern1 = '<[^>]*>'\n",
    "        title = re.sub(pattern=pattern1, repl='', string=str(title))\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "\n",
    "        news_titles.append(title)\n",
    "        news_contents.append(content)\n",
    "\n",
    "        # html_date = news_html.select_one(\"div#ct > div.media_end_head > div.media_end_head_info > div span\")\n",
    "        # news_date = html_date.attrs['data-date-time']\n",
    "        # news_dates.append(news_date)\n",
    "\n",
    "        try:\n",
    "            html_date = news_html.select_one(\"div#ct > div.media_end_head > div.media_end_head_info > div span\")\n",
    "            news_date = html_date.attrs['data-date-time']\n",
    "        except AttributeError:\n",
    "            news_date = news_html.select_one(\"#content > div.end_ct > div > div.article_info > span > em\")\n",
    "            news_date = re.sub(pattern=pattern1,repl='',string=str(news_date))\n",
    "        # 날짜 가져오기\n",
    "        news_dates.append(news_date)\n",
    "\n",
    "    a = pd.DataFrame({'date':news_dates,'title':news_titles,'link':final_urls,'content':news_contents})\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kospi = pd.read_csv('D:\\\\big16\\\\final project\\\\DATA\\\\KOSPI200.csv', encoding='euc-kr')\n",
    "# kospi200 = kospi['종목명']\n",
    "# kospi200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021.07.01', '2021.08.01', '2021.09.01', '2021.10.01', '2021.11.01', '2021.12.01']\n"
     ]
    }
   ],
   "source": [
    "day = []\n",
    "i = 7\n",
    "while i<13:\n",
    "    day.append('2021.{}.01'.format(str(i).zfill(2)))\n",
    "    i += 1\n",
    "\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021.07.01', '2021.08.01', '2021.09.01', '2021.10.01', '2021.11.01', '2021.12.01', '2022.01.01', '2022.02.01', '2022.03.01', '2022.04.01', '2022.05.01', '2022.06.01', '2022.07.01', '2022.08.01', '2022.09.01', '2022.10.01', '2022.11.01', '2022.12.01']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while i<13:\n",
    "    day.append('2022.{}.01'.format(str(i).zfill(2)))\n",
    "    i += 1\n",
    "\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021.07.01', '2021.08.01', '2021.09.01', '2021.10.01', '2021.11.01', '2021.12.01', '2022.01.01', '2022.02.01', '2022.03.01', '2022.04.01', '2022.05.01', '2022.06.01', '2022.07.01', '2022.08.01', '2022.09.01', '2022.10.01', '2022.11.01', '2022.12.01', '2023.01.01', '2023.02.01', '2023.03.01', '2023.04.01', '2023.05.01', '2023.06.01']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while i<7:\n",
    "    day.append('2023.{}.01'.format(str(i).zfill(2)))\n",
    "    i += 1\n",
    "\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m page \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \n\u001b[0;32m     24\u001b[0m maxpage_t \u001b[39m=\u001b[39m(\u001b[39mint\u001b[39m(maxpage)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m   \u001b[39m# 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m a \u001b[39m=\u001b[39m crawling_all(search,page,maxpage_t, sort, s_date, e_date, s_from, e_to)\n\u001b[0;32m     27\u001b[0m news_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([news_df, a], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, keys\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m news_df \u001b[39m=\u001b[39m news_df\u001b[39m.\u001b[39mdrop_duplicates(keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m,ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mcrawling_all\u001b[1;34m(search, page, maxpage_t, sort, s_date, e_date, s_from, e_to)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m page \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m maxpage_t :\n\u001b[0;32m     12\u001b[0m     url_origin \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://search.naver.com/search.naver?where=news&query=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m search \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m&sort=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39msort\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m&ds=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m s_date \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m&de=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m e_date \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m&nso=so\u001b[39m\u001b[39m%\u001b[39m\u001b[39m3Ar\u001b[39m\u001b[39m%\u001b[39m\u001b[39m2Cp\u001b[39m\u001b[39m%\u001b[39m\u001b[39m3Afrom\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m s_from \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m e_to \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m2Ca\u001b[39m\u001b[39m%\u001b[39m\u001b[39m3A&start=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(page)\n\u001b[1;32m---> 13\u001b[0m     url \u001b[39m=\u001b[39m articles_crawler(url_origin)\n\u001b[0;32m     14\u001b[0m     news_url \u001b[39m.\u001b[39mappend(url)\n\u001b[0;32m     15\u001b[0m     page \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36marticles_crawler\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39marticles_crawler\u001b[39m(url):\n\u001b[0;32m     26\u001b[0m     \u001b[39m#html 불러오기\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     original_html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mheaders, verify\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     29\u001b[0m     html \u001b[39m=\u001b[39m BeautifulSoup(original_html\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     url_naver \u001b[39m=\u001b[39m html\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39mdiv.group_news > ul.list_news > li div.news_area > div.news_info > div.info_group > a.info\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1056\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1057\u001b[0m         (\n\u001b[0;32m   1058\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1064\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    411\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs\n\u001b[0;32m    412\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(context, \u001b[39m\"\u001b[39m\u001b[39mload_default_certs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    436\u001b[0m     default_ssl_context\n\u001b[0;32m    437\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    439\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock\u001b[39m.\u001b[39mversion() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mTLSv1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTLSv1.1\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    440\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    437\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[0;32m    446\u001b[0m     )\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    507\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    510\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    513\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    514\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    515\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    516\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    517\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    518\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    519\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    520\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m   1068\u001b[0m             \u001b[39m# non-blocking\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1070\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1071\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1072\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1339\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mand\u001b[39;00m block:\n\u001b[0;32m   1340\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1341\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1342\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#데이터 프레임 만들기\n",
    "news_df = news_df = pd.DataFrame(\n",
    "    data=None\n",
    "    , index=None\n",
    "    , columns=['date','title','link''content']\n",
    ")\n",
    "\n",
    "# 최대 페이지 수\n",
    "maxpage = 401\n",
    "#검색어 입력\n",
    "search = '연구개발'\n",
    "# 검색 방식\n",
    "sort = '0'\n",
    "# 시작날짜\n",
    "s_date = '2021.06.28'\n",
    "# 끝나는 날짜\n",
    "e_date = '2021.06.30'\n",
    "\n",
    "# 날짜 바꾸기\n",
    "s_from = s_date.replace(\".\",\"\")\n",
    "e_to = e_date.replace(\".\",\"\")\n",
    "\n",
    "page = 1  \n",
    "maxpage_t =(int(maxpage)-1)*10+1   # 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\n",
    "\n",
    "a = crawling_all(search,page,maxpage_t, sort, s_date, e_date, s_from, e_to)\n",
    "news_df = pd.concat([news_df, a], ignore_index=True, keys=['date','title','link''content'])\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "\n",
    "now = datetime.now()\n",
    "news_df.to_csv('D:\\\\big16\\\\final project\\\\DATA\\\\NEWS_DATA\\\\기술혁신\\\\{}_date{}_{}.csv'.format(search,s_from, e_to),encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'D:\\big16\\final project\\DATA\\NEWS_DATA\\기술혁신'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m news_df \u001b[39m=\u001b[39m news_df\u001b[39m.\u001b[39mdrop_duplicates(keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m,ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m now \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m---> 36\u001b[0m news_df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mbig16\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mfinal project\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDATA\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mNEWS_DATA\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m기술혁신\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m{}\u001b[39;49;00m\u001b[39m_date\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(search,s_from, e_to),encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8-sig\u001b[39;49m\u001b[39m'\u001b[39;49m,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tj\\anaconda3\\envs\\trading\\lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'D:\\big16\\final project\\DATA\\NEWS_DATA\\기술혁신'"
     ]
    }
   ],
   "source": [
    "#####뉴스크롤링 시작#####\n",
    "for i in tqdm(day) :\n",
    "    #데이터 프레임 만들기\n",
    "    news_df = news_df = pd.DataFrame(\n",
    "        data=None\n",
    "        , index=None\n",
    "        , columns=['date','title','link''content']\n",
    "    )\n",
    "\n",
    "    # 최대 페이지 수\n",
    "    maxpage = 401\n",
    "    #검색어 입력\n",
    "    search = '연구개발'\n",
    "    # 검색 방식\n",
    "    sort = str(0)\n",
    "    # 시작날짜\n",
    "    s_date = i\n",
    "    # 끝나는 날짜\n",
    "    e_1 = i[-2:]\n",
    "    e_2 = int(e_1)+30\n",
    "    e_3 = i[:-2]+str(e_2)\n",
    "    e_date = e_3\n",
    "\n",
    "    # 날짜 바꾸기\n",
    "    s_from = s_date.replace(\".\",\"\")\n",
    "    e_to = e_date.replace(\".\",\"\")\n",
    "\n",
    "    page = 1  \n",
    "    maxpage_t =(int(maxpage)-1)*10+1   # 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\n",
    "\n",
    "    a = crawling_all(search,page,maxpage_t, sort, s_date, e_date, s_from, e_to)\n",
    "    news_df = pd.concat([news_df, a], ignore_index=True, keys=['date','title','link''content'])\n",
    "    news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "\n",
    "    now = datetime.now()\n",
    "    news_df.to_csv('D:\\\\big16\\\\final project\\\\DATA\\\\NEWS_DATA\\\\기술혁신\\\\{}_date{}_{}.csv'.format(search,s_from, e_to),encoding='utf-8-sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 프레임 만들기\n",
    "news_df = news_df = pd.DataFrame(\n",
    "    data=None\n",
    "    , index=None\n",
    "    , columns=['date','title','link''content']\n",
    ")\n",
    "\n",
    "# 최대 페이지 수\n",
    "maxpage = 401\n",
    "#검색어 입력\n",
    "search = '연구개발'\n",
    "# 검색 방식\n",
    "sort = '0'\n",
    "# 시작날짜\n",
    "s_date = '2023.07.01'\n",
    "# 끝나는 날짜\n",
    "e_date = '2023.07.10'\n",
    "\n",
    "# 날짜 바꾸기\n",
    "s_from = s_date.replace(\".\",\"\")\n",
    "e_to = e_date.replace(\".\",\"\")\n",
    "\n",
    "page = 1  \n",
    "maxpage_t =(int(maxpage)-1)*10+1   # 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\n",
    "\n",
    "a = crawling_all(search,page,maxpage_t, sort, s_date, e_date, s_from, e_to)\n",
    "news_df = pd.concat([news_df, a], ignore_index=True, keys=['date','title','link''content'])\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "\n",
    "now = datetime.now()\n",
    "news_df.to_csv('D:\\\\big16\\\\final project\\\\DATA\\\\NEWS_DATA\\\\기술혁신\\\\{}_date{}_{}.csv'.format(search,s_from, e_to),encoding='utf-8-sig',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
