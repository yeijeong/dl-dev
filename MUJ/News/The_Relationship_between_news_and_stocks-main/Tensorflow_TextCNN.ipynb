{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextCNN (ver.Kkma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, Dense, GRU, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(\n",
    "                        user    = 'stocks',\n",
    "                        passwd  = 'Stocks!',\n",
    "                        host    = \"-\",\n",
    "                        port    = 3306,\n",
    "                        db      = 'Data',\n",
    "                        charset = 'utf8'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000060</td>\n",
       "      <td>2500억 모집액 못 채우고 미달 3년물 2200억에 1710억 모집 5년물 전액 ...</td>\n",
       "      <td>2022-07-15 19:54:00</td>\n",
       "      <td>['2500', '억', '모집', '액', '못', '채우', '고', '미달',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000060</td>\n",
       "      <td>메리츠증권은 14일 아모레G에 대해 아모레퍼시픽 부진으로 투자 매력도가 상대적으로 ...</td>\n",
       "      <td>2022-07-14 08:36:00</td>\n",
       "      <td>['메리츠증권', '은', '14', '일', '아모레', 'G', '에', '대하...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000060</td>\n",
       "      <td>증시 과매도 PER 종목 쏟아진다 30개 PER 1 2배로 떨어져 PER 낮은 기업...</td>\n",
       "      <td>2022-07-13 17:36:00</td>\n",
       "      <td>['증시', '과', '매도', 'PER', '종목', '쏟아지', 'ㄴ다', '3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000060</td>\n",
       "      <td>투자의견 매수 목표주가 7만5000원 유지 메리츠증권이 13일 SK텔레콤에 대해 2...</td>\n",
       "      <td>2022-07-13 08:18:00</td>\n",
       "      <td>['투자', '의견', '매수', '목표', '주가', '7', '만', '5000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000060</td>\n",
       "      <td>금감원 손보사에 유사암 일반암 진단비 자료 요구 올해들어 손보사 유사암 경쟁 진단비...</td>\n",
       "      <td>2022-07-13 06:01:00</td>\n",
       "      <td>['금감원', '손보사', '에', '유사', '암', '일반', '암', '진단'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111614</th>\n",
       "      <td>402340</td>\n",
       "      <td>앱출석 후 회원가입시 80만명 한정 선착순국내 최초 가상자산 거래소 코빗이 4월 한...</td>\n",
       "      <td>2022-04-01 11:17:00</td>\n",
       "      <td>['앱', '출석', '후', '회원', '가', '입시', '80', '만', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111615</th>\n",
       "      <td>402340</td>\n",
       "      <td>SK그룹 투자회사 SK스퀘어의 연결대상 종속회사 원스토어와 SK쉴더스가 증권신고서를...</td>\n",
       "      <td>2022-04-01 11:06:00</td>\n",
       "      <td>['SK', '그룹', '투자', '회사', 'SK', '스퀘어', '의', '연결...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111616</th>\n",
       "      <td>402340</td>\n",
       "      <td>31일 증권신고서 제출 4월 기관 수요예측 SK스퀘어 자회사들인 토종 앱스토어 원스...</td>\n",
       "      <td>2022-04-01 09:00:00</td>\n",
       "      <td>['31', '일', '증권', '신고서', '제출', '4', '월', '기관',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111617</th>\n",
       "      <td>402340</td>\n",
       "      <td>삼부토건 제3자 배정증자 방식으로 SK에코플랜트에 보통주 11만 6106주 유상증...</td>\n",
       "      <td>2022-04-01 07:01:00</td>\n",
       "      <td>['삼부', '토건', '제', '3', '자', '배정', '증자', '방식', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111618</th>\n",
       "      <td>402340</td>\n",
       "      <td>1Q 상장한 21개 종목 중 8개 종목은 공모가 하회 금리인상 우려에 우크라이나까지...</td>\n",
       "      <td>2022-04-01 06:06:00</td>\n",
       "      <td>['1', 'Q', '상장', '하', 'ㄴ', '21', '개', '종목', '중...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111619 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_id                                               text  \\\n",
       "0        000060  2500억 모집액 못 채우고 미달 3년물 2200억에 1710억 모집 5년물 전액 ...   \n",
       "1        000060  메리츠증권은 14일 아모레G에 대해 아모레퍼시픽 부진으로 투자 매력도가 상대적으로 ...   \n",
       "2        000060  증시 과매도 PER 종목 쏟아진다 30개 PER 1 2배로 떨어져 PER 낮은 기업...   \n",
       "3        000060  투자의견 매수 목표주가 7만5000원 유지 메리츠증권이 13일 SK텔레콤에 대해 2...   \n",
       "4        000060  금감원 손보사에 유사암 일반암 진단비 자료 요구 올해들어 손보사 유사암 경쟁 진단비...   \n",
       "...         ...                                                ...   \n",
       "111614   402340  앱출석 후 회원가입시 80만명 한정 선착순국내 최초 가상자산 거래소 코빗이 4월 한...   \n",
       "111615   402340  SK그룹 투자회사 SK스퀘어의 연결대상 종속회사 원스토어와 SK쉴더스가 증권신고서를...   \n",
       "111616   402340  31일 증권신고서 제출 4월 기관 수요예측 SK스퀘어 자회사들인 토종 앱스토어 원스...   \n",
       "111617   402340   삼부토건 제3자 배정증자 방식으로 SK에코플랜트에 보통주 11만 6106주 유상증...   \n",
       "111618   402340  1Q 상장한 21개 종목 중 8개 종목은 공모가 하회 금리인상 우려에 우크라이나까지...   \n",
       "\n",
       "                      date                                              token  \\\n",
       "0      2022-07-15 19:54:00  ['2500', '억', '모집', '액', '못', '채우', '고', '미달',...   \n",
       "1      2022-07-14 08:36:00  ['메리츠증권', '은', '14', '일', '아모레', 'G', '에', '대하...   \n",
       "2      2022-07-13 17:36:00  ['증시', '과', '매도', 'PER', '종목', '쏟아지', 'ㄴ다', '3...   \n",
       "3      2022-07-13 08:18:00  ['투자', '의견', '매수', '목표', '주가', '7', '만', '5000...   \n",
       "4      2022-07-13 06:01:00  ['금감원', '손보사', '에', '유사', '암', '일반', '암', '진단'...   \n",
       "...                    ...                                                ...   \n",
       "111614 2022-04-01 11:17:00  ['앱', '출석', '후', '회원', '가', '입시', '80', '만', '...   \n",
       "111615 2022-04-01 11:06:00  ['SK', '그룹', '투자', '회사', 'SK', '스퀘어', '의', '연결...   \n",
       "111616 2022-04-01 09:00:00  ['31', '일', '증권', '신고서', '제출', '4', '월', '기관',...   \n",
       "111617 2022-04-01 07:01:00  ['삼부', '토건', '제', '3', '자', '배정', '증자', '방식', ...   \n",
       "111618 2022-04-01 06:06:00  ['1', 'Q', '상장', '하', 'ㄴ', '21', '개', '종목', '중...   \n",
       "\n",
       "        label  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "111614      1  \n",
       "111615      1  \n",
       "111616      1  \n",
       "111617      1  \n",
       "111618      1  \n",
       "\n",
       "[111619 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SELECT stock_id, text, date, token, label FROM Token'\n",
    "news = pd.read_sql(sql, conn)\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def str_to_list(d):\n",
    "  text = re.sub(r'[\\[\\'\\]]', '', d)\n",
    "  return text.split(\", \")\n",
    "\n",
    "news[\"token\"] = news.token.apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111619/111619 [05:56<00:00, 312.94it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000060</td>\n",
       "      <td>2500억 모집액 못 채우고 미달 3년물 2200억에 1710억 모집 5년물 전액 ...</td>\n",
       "      <td>2022-07-15 19:54:00</td>\n",
       "      <td>[억, 모집, 액, 못, 채우, 고, 미달, 년, 물, 억, 억, 모, 집, 년, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000060</td>\n",
       "      <td>메리츠증권은 14일 아모레G에 대해 아모레퍼시픽 부진으로 투자 매력도가 상대적으로 ...</td>\n",
       "      <td>2022-07-14 08:36:00</td>\n",
       "      <td>[메리츠증권, 일, 아모레, G, 대하, 어, 아모레, 퍼시픽, 부진, 투자, 매력...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000060</td>\n",
       "      <td>증시 과매도 PER 종목 쏟아진다 30개 PER 1 2배로 떨어져 PER 낮은 기업...</td>\n",
       "      <td>2022-07-13 17:36:00</td>\n",
       "      <td>[증시, 매도, PER, 종목, 쏟아지, ㄴ다, 개, PER, 배, 로, 떨어지, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000060</td>\n",
       "      <td>투자의견 매수 목표주가 7만5000원 유지 메리츠증권이 13일 SK텔레콤에 대해 2...</td>\n",
       "      <td>2022-07-13 08:18:00</td>\n",
       "      <td>[투자, 의견, 매수, 목표, 주가, 만, 원, 유지, 메리츠증권, 일, SK, 텔...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000060</td>\n",
       "      <td>금감원 손보사에 유사암 일반암 진단비 자료 요구 올해들어 손보사 유사암 경쟁 진단비...</td>\n",
       "      <td>2022-07-13 06:01:00</td>\n",
       "      <td>[금감원, 손보사, 유사, 암, 일반, 암, 진단, 비, 자료, 요구, 올해, 듣,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111614</th>\n",
       "      <td>402340</td>\n",
       "      <td>앱출석 후 회원가입시 80만명 한정 선착순국내 최초 가상자산 거래소 코빗이 4월 한...</td>\n",
       "      <td>2022-04-01 11:17:00</td>\n",
       "      <td>[앱, 출석, 후, 회원, 입시, 만, 명, 한정, 선착순, 국내, 최초, 가상, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111615</th>\n",
       "      <td>402340</td>\n",
       "      <td>SK그룹 투자회사 SK스퀘어의 연결대상 종속회사 원스토어와 SK쉴더스가 증권신고서를...</td>\n",
       "      <td>2022-04-01 11:06:00</td>\n",
       "      <td>[SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종속, 회사, 원, 스...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111616</th>\n",
       "      <td>402340</td>\n",
       "      <td>31일 증권신고서 제출 4월 기관 수요예측 SK스퀘어 자회사들인 토종 앱스토어 원스...</td>\n",
       "      <td>2022-04-01 09:00:00</td>\n",
       "      <td>[일, 증권, 신고서, 제출, 월, 기관, 수요, 예측, SK, 스퀘어, 자회사, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111617</th>\n",
       "      <td>402340</td>\n",
       "      <td>삼부토건 제3자 배정증자 방식으로 SK에코플랜트에 보통주 11만 6106주 유상증...</td>\n",
       "      <td>2022-04-01 07:01:00</td>\n",
       "      <td>[삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 만, 주...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111618</th>\n",
       "      <td>402340</td>\n",
       "      <td>1Q 상장한 21개 종목 중 8개 종목은 공모가 하회 금리인상 우려에 우크라이나까지...</td>\n",
       "      <td>2022-04-01 06:06:00</td>\n",
       "      <td>[Q, 상장, ㄴ, 개, 종목, 중, 개, 종목, 공모, 하회, 금리, 인상, 우려...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111619 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_id                                               text  \\\n",
       "0        000060  2500억 모집액 못 채우고 미달 3년물 2200억에 1710억 모집 5년물 전액 ...   \n",
       "1        000060  메리츠증권은 14일 아모레G에 대해 아모레퍼시픽 부진으로 투자 매력도가 상대적으로 ...   \n",
       "2        000060  증시 과매도 PER 종목 쏟아진다 30개 PER 1 2배로 떨어져 PER 낮은 기업...   \n",
       "3        000060  투자의견 매수 목표주가 7만5000원 유지 메리츠증권이 13일 SK텔레콤에 대해 2...   \n",
       "4        000060  금감원 손보사에 유사암 일반암 진단비 자료 요구 올해들어 손보사 유사암 경쟁 진단비...   \n",
       "...         ...                                                ...   \n",
       "111614   402340  앱출석 후 회원가입시 80만명 한정 선착순국내 최초 가상자산 거래소 코빗이 4월 한...   \n",
       "111615   402340  SK그룹 투자회사 SK스퀘어의 연결대상 종속회사 원스토어와 SK쉴더스가 증권신고서를...   \n",
       "111616   402340  31일 증권신고서 제출 4월 기관 수요예측 SK스퀘어 자회사들인 토종 앱스토어 원스...   \n",
       "111617   402340   삼부토건 제3자 배정증자 방식으로 SK에코플랜트에 보통주 11만 6106주 유상증...   \n",
       "111618   402340  1Q 상장한 21개 종목 중 8개 종목은 공모가 하회 금리인상 우려에 우크라이나까지...   \n",
       "\n",
       "                      date                                              token  \\\n",
       "0      2022-07-15 19:54:00  [억, 모집, 액, 못, 채우, 고, 미달, 년, 물, 억, 억, 모, 집, 년, ...   \n",
       "1      2022-07-14 08:36:00  [메리츠증권, 일, 아모레, G, 대하, 어, 아모레, 퍼시픽, 부진, 투자, 매력...   \n",
       "2      2022-07-13 17:36:00  [증시, 매도, PER, 종목, 쏟아지, ㄴ다, 개, PER, 배, 로, 떨어지, ...   \n",
       "3      2022-07-13 08:18:00  [투자, 의견, 매수, 목표, 주가, 만, 원, 유지, 메리츠증권, 일, SK, 텔...   \n",
       "4      2022-07-13 06:01:00  [금감원, 손보사, 유사, 암, 일반, 암, 진단, 비, 자료, 요구, 올해, 듣,...   \n",
       "...                    ...                                                ...   \n",
       "111614 2022-04-01 11:17:00  [앱, 출석, 후, 회원, 입시, 만, 명, 한정, 선착순, 국내, 최초, 가상, ...   \n",
       "111615 2022-04-01 11:06:00  [SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종속, 회사, 원, 스...   \n",
       "111616 2022-04-01 09:00:00  [일, 증권, 신고서, 제출, 월, 기관, 수요, 예측, SK, 스퀘어, 자회사, ...   \n",
       "111617 2022-04-01 07:01:00  [삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 만, 주...   \n",
       "111618 2022-04-01 06:06:00  [Q, 상장, ㄴ, 개, 종목, 중, 개, 종목, 공모, 하회, 금리, 인상, 우려...   \n",
       "\n",
       "        label  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "111614      1  \n",
       "111615      1  \n",
       "111616      1  \n",
       "111617      1  \n",
       "111618      1  \n",
       "\n",
       "[111619 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def stopword(x):\n",
    "  stopword = [r'상승.*', r'하락.*', r'급등.*', r'급락.*', '상승세', '하락세', '폭등', '폭락', '오름세', '약세', '강세', '의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다', '에', '은', '는', '하']\n",
    "  return [i for i in x if i not in stopword and not i.isdigit()]\n",
    "tqdm.pandas()\n",
    "news[\"token\"] = news.token.progress_apply(stopword)\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94918,) (94918,) (16701,) (16701,)\n"
     ]
    }
   ],
   "source": [
    "test = news.loc[news[\"date\"] >= '2022-07-01 00:00:00']\n",
    "train = news.loc[news[\"date\"] < '2022-07-01 00:00:00']\n",
    "\n",
    "X_train = train['token']\n",
    "y_train = train['label']\n",
    "X_test = test['token']\n",
    "y_test = test['label']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 62463\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 18802\n",
      "단어 집합에서 희귀 단어의 비율: 30.101019803723805\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.07036167954849475\n"
     ]
    }
   ],
   "source": [
    "threshold = 4\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 43662\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94918\n",
      "94918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/numpy/lib/function_base.py:5071: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 최대 길이: 5759\n",
      "리뷰 평균 길이: 489.9088054952696\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 최대 길이:', max(len(l) for l in X_train))\n",
    "print('리뷰 평균 길이:', sum(map(len, X_train)) / len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = max_len # 임베딩 벡터의 차원\n",
    "dropout_ratio = 0.4 # 드롭아웃 비율\n",
    "num_filters = 2 # 커널의 수\n",
    "kernel_size = 3 # 커널의 크기\n",
    "hidden_units = 128 # 뉴런의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 23:41:54.361285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 800)         34929600  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 800)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 2)           4802      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 2)                0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               384       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,934,915\n",
      "Trainable params: 34,934,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding = 'valid', activation = 'relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "mc = ModelCheckpoint('TextCNN_best_model(learning_rate).h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.6907 - acc: 0.5297\n",
      "Epoch 1: val_acc improved from -inf to 0.52797, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1064s 2s/step - loss: 0.6907 - acc: 0.5297 - val_loss: 0.6931 - val_acc: 0.5280\n",
      "Epoch 2/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.6788 - acc: 0.5653\n",
      "Epoch 2: val_acc improved from 0.52797 to 0.55410, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1035s 2s/step - loss: 0.6788 - acc: 0.5653 - val_loss: 0.6805 - val_acc: 0.5541\n",
      "Epoch 3/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.6541 - acc: 0.6121\n",
      "Epoch 3: val_acc improved from 0.55410 to 0.57101, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1044s 2s/step - loss: 0.6541 - acc: 0.6121 - val_loss: 0.6767 - val_acc: 0.5710\n",
      "Epoch 4/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.6279 - acc: 0.6487\n",
      "Epoch 4: val_acc improved from 0.57101 to 0.58497, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1036s 2s/step - loss: 0.6279 - acc: 0.6487 - val_loss: 0.6930 - val_acc: 0.5850\n",
      "Epoch 5/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.6013 - acc: 0.6755\n",
      "Epoch 5: val_acc improved from 0.58497 to 0.58865, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1061s 2s/step - loss: 0.6013 - acc: 0.6755 - val_loss: 0.6948 - val_acc: 0.5887\n",
      "Epoch 6/10\n",
      "594/594 [==============================] - ETA: 0s - loss: 0.5801 - acc: 0.6975\n",
      "Epoch 6: val_acc improved from 0.58865 to 0.59366, saving model to TextCNN_best_model(learning_rate).h5\n",
      "594/594 [==============================] - 1034s 2s/step - loss: 0.5801 - acc: 0.6975 - val_loss: 0.6938 - val_acc: 0.5937\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.005), loss='binary_crossentropy', metrics = ['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split = 0.2, callbacks=[es, mc], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/522 [==============================] - 23s 44ms/step - loss: 0.7671 - acc: 0.5022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.767128586769104, 0.5021855235099792]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('TextCNN_best_model(learning_rate).h5')\n",
    "loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextCNN (ver. Okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT token, label FROM Okt_Token': (1412, 'Table definition has changed, please retry transaction')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2020\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2021\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/cursors.py:148\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    146\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 148\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[1;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/cursors.py:310\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[0;32m--> 310\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[1;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:548\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 548\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:775\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    774\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 775\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    776\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:1163\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_result_packet(first_packet)\n\u001b[1;32m   1164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:1236\u001b[0m, in \u001b[0;36mMySQLResult._read_result_packet\u001b[0;34m(self, first_packet)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_descriptions()\n\u001b[0;32m-> 1236\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_rowdata_packet()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:1270\u001b[0m, in \u001b[0;36mMySQLResult._read_rowdata_packet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1270\u001b[0m     packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()\n\u001b[1;32m   1271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_packet_is_eof(packet):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/connections.py:725\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     packet\u001b[39m.\u001b[39;49mraise_for_error()\n\u001b[1;32m    726\u001b[0m \u001b[39mreturn\u001b[39;00m packet\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39merrno =\u001b[39m\u001b[39m\"\u001b[39m, errno)\n\u001b[0;32m--> 221\u001b[0m err\u001b[39m.\u001b[39;49mraise_mysql_exception(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pymysql/err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    142\u001b[0m     errorclass \u001b[39m=\u001b[39m InternalError \u001b[39mif\u001b[39;00m errno \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m \u001b[39melse\u001b[39;00m OperationalError\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (1412, 'Table definition has changed, please retry transaction')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/jjwani/Downloads/Tensorflow_TextCNN.ipynb 셀 27\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jjwani/Downloads/Tensorflow_TextCNN.ipynb#ch0000039?line=0'>1</a>\u001b[0m sql \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSELECT token, label FROM Okt_Token\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jjwani/Downloads/Tensorflow_TextCNN.ipynb#ch0000039?line=1'>2</a>\u001b[0m okt_token \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(sql, conn)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jjwani/Downloads/Tensorflow_TextCNN.ipynb#ch0000039?line=2'>3</a>\u001b[0m okt_token\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    563\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 566\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    567\u001b[0m         sql,\n\u001b[1;32m    568\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    569\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    570\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    571\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    572\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    575\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   2069\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2070\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2076\u001b[0m     dtype: DtypeArg \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2077\u001b[0m ):\n\u001b[1;32m   2079\u001b[0m     args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 2080\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   2081\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[1;32m   2083\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/pandas/io/sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2032\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT token, label FROM Okt_Token': (1412, 'Table definition has changed, please retry transaction')"
     ]
    }
   ],
   "source": [
    "sql = 'SELECT token, label FROM Okt_Token'\n",
    "okt_token = pd.read_sql(sql, conn)\n",
    "okt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def str_to_list(d):\n",
    "  text = re.sub(r'[\\[\\'\\]]', '', d)\n",
    "  return text.split(\", \")\n",
    "\n",
    "okt_token[\"token\"] = okt_token.token.apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111619/111619 [02:02<00:00, 907.78it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2500억, 모집, 액, 못, 채우고, 미달, 3년, 물, 2200억, 1710억...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[메, 리츠, 증권, 14일, 아모레, G, 대해, 아모레퍼시픽, 부진, 투자, 매...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[증시, 매도, PER, 종목, 쏟아진다, 개, PER, 배, 로, 떨어져, PER...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[투자, 의견, 매수, 목표, 주가, 7만, 5000원, 유지, 메, 리츠, 증권,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[금감원, 손, 보사, 유사, 암, 일반, 암, 진, 단비, 자료, 요구, 올해, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111614</th>\n",
       "      <td>[앱, 출석, 후, 회원, 입시, 80만, 명, 한정, 선착순, 국내, 최초, 가상...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111615</th>\n",
       "      <td>[SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종, 속, 회사, 원,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111616</th>\n",
       "      <td>[31일, 증권, 신고, 서, 제출, 4월, 기관, 수요, 예측, SK, 스퀘어, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111617</th>\n",
       "      <td>[삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 11만,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111618</th>\n",
       "      <td>[Q, 상장, 개, 종목, 중, 개, 종목, 공모, 회, 금리, 인상, 우려, 우크...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    token  label\n",
       "0       [2500억, 모집, 액, 못, 채우고, 미달, 3년, 물, 2200억, 1710억...      1\n",
       "1       [메, 리츠, 증권, 14일, 아모레, G, 대해, 아모레퍼시픽, 부진, 투자, 매...      0\n",
       "2       [증시, 매도, PER, 종목, 쏟아진다, 개, PER, 배, 로, 떨어져, PER...      1\n",
       "3       [투자, 의견, 매수, 목표, 주가, 7만, 5000원, 유지, 메, 리츠, 증권,...      0\n",
       "4       [금감원, 손, 보사, 유사, 암, 일반, 암, 진, 단비, 자료, 요구, 올해, ...      0\n",
       "...                                                   ...    ...\n",
       "111614  [앱, 출석, 후, 회원, 입시, 80만, 명, 한정, 선착순, 국내, 최초, 가상...      1\n",
       "111615  [SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종, 속, 회사, 원,...      1\n",
       "111616  [31일, 증권, 신고, 서, 제출, 4월, 기관, 수요, 예측, SK, 스퀘어, ...      1\n",
       "111617  [삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 11만,...      1\n",
       "111618  [Q, 상장, 개, 종목, 중, 개, 종목, 공모, 회, 금리, 인상, 우려, 우크...      1\n",
       "\n",
       "[111619 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def stopword(x):\n",
    "  stopword = [r'상승.*', r'하락.*', r'급등.*', r'급락.*', '상승세', '하락세', '폭등', '폭락', '오름세', '약세', '강세', '의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다', '에', '은', '는', '하']\n",
    "  return [i for i in x if i not in stopword and not i.isdigit()]\n",
    "tqdm.pandas()\n",
    "okt_token[\"token\"] = okt_token.token.progress_apply(stopword)\n",
    "okt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-15 19:54:00</td>\n",
       "      <td>[2500억, 모집, 액, 못, 채우고, 미달, 3년, 물, 2200억, 1710억...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-14 08:36:00</td>\n",
       "      <td>[메, 리츠, 증권, 14일, 아모레, G, 대해, 아모레퍼시픽, 부진, 투자, 매...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-13 17:36:00</td>\n",
       "      <td>[증시, 매도, PER, 종목, 쏟아진다, 개, PER, 배, 로, 떨어져, PER...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-13 08:18:00</td>\n",
       "      <td>[투자, 의견, 매수, 목표, 주가, 7만, 5000원, 유지, 메, 리츠, 증권,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-13 06:01:00</td>\n",
       "      <td>[금감원, 손, 보사, 유사, 암, 일반, 암, 진, 단비, 자료, 요구, 올해, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111614</th>\n",
       "      <td>2022-04-01 11:17:00</td>\n",
       "      <td>[앱, 출석, 후, 회원, 입시, 80만, 명, 한정, 선착순, 국내, 최초, 가상...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111615</th>\n",
       "      <td>2022-04-01 11:06:00</td>\n",
       "      <td>[SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종, 속, 회사, 원,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111616</th>\n",
       "      <td>2022-04-01 09:00:00</td>\n",
       "      <td>[31일, 증권, 신고, 서, 제출, 4월, 기관, 수요, 예측, SK, 스퀘어, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111617</th>\n",
       "      <td>2022-04-01 07:01:00</td>\n",
       "      <td>[삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 11만,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111618</th>\n",
       "      <td>2022-04-01 06:06:00</td>\n",
       "      <td>[Q, 상장, 개, 종목, 중, 개, 종목, 공모, 회, 금리, 인상, 우려, 우크...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              token  \\\n",
       "0      2022-07-15 19:54:00  [2500억, 모집, 액, 못, 채우고, 미달, 3년, 물, 2200억, 1710억...   \n",
       "1      2022-07-14 08:36:00  [메, 리츠, 증권, 14일, 아모레, G, 대해, 아모레퍼시픽, 부진, 투자, 매...   \n",
       "2      2022-07-13 17:36:00  [증시, 매도, PER, 종목, 쏟아진다, 개, PER, 배, 로, 떨어져, PER...   \n",
       "3      2022-07-13 08:18:00  [투자, 의견, 매수, 목표, 주가, 7만, 5000원, 유지, 메, 리츠, 증권,...   \n",
       "4      2022-07-13 06:01:00  [금감원, 손, 보사, 유사, 암, 일반, 암, 진, 단비, 자료, 요구, 올해, ...   \n",
       "...                    ...                                                ...   \n",
       "111614 2022-04-01 11:17:00  [앱, 출석, 후, 회원, 입시, 80만, 명, 한정, 선착순, 국내, 최초, 가상...   \n",
       "111615 2022-04-01 11:06:00  [SK, 그룹, 투자, 회사, SK, 스퀘어, 연결, 대상, 종, 속, 회사, 원,...   \n",
       "111616 2022-04-01 09:00:00  [31일, 증권, 신고, 서, 제출, 4월, 기관, 수요, 예측, SK, 스퀘어, ...   \n",
       "111617 2022-04-01 07:01:00  [삼부, 토건, 제, 배정, 증자, 방식, SK, 에코, 플랜트, 보통주, 11만,...   \n",
       "111618 2022-04-01 06:06:00  [Q, 상장, 개, 종목, 중, 개, 종목, 공모, 회, 금리, 인상, 우려, 우크...   \n",
       "\n",
       "        label  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "111614      1  \n",
       "111615      1  \n",
       "111616      1  \n",
       "111617      1  \n",
       "111618      1  \n",
       "\n",
       "[111619 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_token = pd.concat([news['date'], okt_token], axis= 1)\n",
    "okt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94918,) (94918,) (16701,) (16701,)\n"
     ]
    }
   ],
   "source": [
    "test = okt_token.loc[okt_token[\"date\"] >= '2022-07-01 00:00:00']\n",
    "train = okt_token.loc[okt_token[\"date\"] < '2022-07-01 00:00:00']\n",
    "\n",
    "X_train = train['token']\n",
    "y_train = train['label']\n",
    "X_test = test['token']\n",
    "y_test = test['label']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 62463\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 18802\n",
      "단어 집합에서 희귀 단어의 비율: 30.101019803723805\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.07036167954849475\n"
     ]
    }
   ],
   "source": [
    "threshold = 4\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 43662\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "\n",
    "X_trian = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('리뷰 최대 길이:', max(len(l) for l in X_train))\n",
    "print('리뷰 평균 길이:', sum(map(len, X_trian)) / len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = max_len # 임베딩 벡터의 차원\n",
    "dropout_ratio = 0.4 # 드롭아웃 비율\n",
    "num_filters = 2 # 커널의 수\n",
    "kernel_size = 3 # 커널의 크기\n",
    "hidden_units = 128 # 뉴런의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding = 'valid', activation = 'relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "mc = ModelCheckpoint('TextCNN_best_model(okt).h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.005), loss='binary_crossentropy', metrics = ['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split = 0.2, callbacks=[es, mc], batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('TextCNN_best_model(okt).h5')\n",
    "loaded_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "974742b9e3f84bbfc2ab858fce40e48c160687419b819993149cbe09d34e2b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
