{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wd\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "\n",
    "def get_article_info(driver, crawl_date, press_list, title_list, link_list, date_list, more_news_base_url=None, more_news=False):\n",
    "    more_news_url_list = []\n",
    "    while True:    \n",
    "        page_html_source = driver.page_source\n",
    "        url_soup = BeautifulSoup(page_html_source, 'lxml')\n",
    "        \n",
    "        more_news_infos = url_soup.select('a.news_more')\n",
    "        \n",
    "        if more_news:\n",
    "            for more_news_info in more_news_infos:\n",
    "                more_news_url = f\"{more_news_base_url}{more_news_info.get('href')}\"\n",
    "\n",
    "                more_news_url_list.append(more_news_url)\n",
    "\n",
    "        article_infos = url_soup.select(\"div.news_area\")\n",
    "        \n",
    "        if not article_infos:\n",
    "            break\n",
    "\n",
    "        for article_info in article_infos:  \n",
    "            press_info = article_info.select_one(\"div.info_group > a.info.press\")\n",
    "            \n",
    "            if press_info is None:\n",
    "                press_info = article_info.select_one(\"div.info_group > span.info.press\")\n",
    "            article = article_info.select_one(\"a.news_tit\")\n",
    "            \n",
    "            press = press_info.text.replace(\"언론사 선정\", \"\")\n",
    "            title = article.get('title')\n",
    "            link = article.get('href')\n",
    "\n",
    "#             print(f\"press - {press} / title - {title} / link - {link}\")\n",
    "            press_list.append(press)\n",
    "            title_list.append(title)\n",
    "            link_list.append(link)\n",
    "            date_list.append(crawl_date)\n",
    "\n",
    "        time.sleep(2.0)\n",
    "                      \n",
    "                      \n",
    "        next_button_status = url_soup.select_one(\"a.btn_next\").get(\"aria-disabled\")\n",
    "        \n",
    "        if next_button_status == 'true':\n",
    "            break\n",
    "        \n",
    "        time.sleep(1.0)\n",
    "        next_page_btn = driver.find_element(By.CSS_SELECTOR,\"a.btn_next\").click()      \n",
    "         \n",
    "    \n",
    "    return press_list, title_list, link_list, more_news_url_list\n",
    "    \n",
    "    \n",
    "\n",
    "def get_naver_news_info_from_selenium(keyword, save_path, target_date, ds_de, sort=0, remove_duplicate=False):\n",
    "    crawl_date = f\"{target_date[:4]}.{target_date[4:6]}.{target_date[6:]}\"\n",
    "    driver = wd.Chrome(\"../../ssuyan/PAST_NEWS/chromedriver_win32.zip/chromedriver\") # chromedriver 파일 경로\n",
    "\n",
    "    encoded_keyword = urllib.parse.quote(keyword)\n",
    "    url = f\"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort={sort}&photo=0&field=0&pd=3&ds={ds_de}&de={ds_de}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{target_date}to{target_date}&is_sug_officeid=0\"\n",
    "    \n",
    "    more_news_base_url = \"https://search.naver.com/search.naver\"\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    press_list, title_list, link_list, date_list, more_news_url_list = [], [], [], [], []\n",
    "    \n",
    "    press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n",
    "                                                                             crawl_date=crawl_date, \n",
    "                                                                             press_list=press_list, \n",
    "                                                                             title_list=title_list, \n",
    "                                                                             link_list=link_list,\n",
    "                                                                             date_list=date_list,\n",
    "                                                                             more_news_base_url=more_news_base_url,\n",
    "                                                                             more_news=True)\n",
    "    driver.close()\n",
    "    \n",
    "    if len(more_news_url_list) > 0:\n",
    "        print(len(more_news_url_list))\n",
    "        more_news_url_list = list(set(more_news_url_list))\n",
    "        print(f\"->{len(more_news_url_list)}\")\n",
    "        for more_news_url in more_news_url_list:\n",
    "            driver = wd.Chrome(\"../../ssuyan/PAST_NEWS/chromedriver_win32.zip/chromedriver\")\n",
    "            driver.get(more_news_url)\n",
    "            \n",
    "            press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n",
    "                                                                             crawl_date=crawl_date, \n",
    "                                                                             press_list=press_list, \n",
    "                                                                             title_list=title_list, \n",
    "                                                                             link_list=link_list,\n",
    "                                                                             date_list=date_list)\n",
    "            driver.close()\n",
    "    article_df = pd.DataFrame({\"날짜\": date_list, \"언론사\": press_list, \"제목\": title_list, \"링크\": link_list})\n",
    "    \n",
    "    print(f\"extract article num : {len(article_df)}\")\n",
    "    if remove_duplicate:\n",
    "        article_df = article_df.drop_duplicates(['링크'], keep='first')\n",
    "        print(f\"after remove duplicate -> {len(article_df)}\")\n",
    "    \n",
    "    article_df.to_excel(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crawl_news_data(keyword, year, month, start_day, end_day, save_path):\n",
    "    for day in tqdm(range(start_day, end_day+1)):\n",
    "        date_time_obj = datetime(year=year, month=month, day=day)\n",
    "        target_date = date_time_obj.strftime(\"%Y%m%d\")\n",
    "        ds_de = date_time_obj.strftime(\"%Y.%m.%d\")\n",
    "\n",
    "        get_naver_news_info_from_selenium(keyword=keyword, save_path=f\"{save_path}/{keyword}/{target_date}_{keyword}_.xlsx\", target_date=target_date, ds_de=ds_de, remove_duplicate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['방위']\n",
    "save_path = \"./naver_news_article_2022\"\n",
    "\n",
    "for keyword in keywords:\n",
    "    os.makedirs(f\"{save_path}/{keyword}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### 2022년 1월 1일 부터 13일까지 값을 크롤링\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start keyword - 방위 crawling ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]C:\\Users\\green\\AppData\\Local\\Temp\\ipykernel_10852\\2950756884.py:63: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = wd.Chrome(\"../../ssuyan/PAST_NEWS/chromedriver_win32.zip/chromedriver\") # chromedriver 파일 경로\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "->4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\AppData\\Local\\Temp\\ipykernel_10852\\2950756884.py:89: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = wd.Chrome(\"../../ssuyan/PAST_NEWS/chromedriver_win32.zip/chromedriver\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract article num : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [01:07<13:27, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "->1\n",
      "extract article num : 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [01:41<08:48, 48.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "->54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [06:13<34:12, 186.63s/it]\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.199)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E7A813+48355]\n\t(No symbol) [0x00E0C4B1]\n\t(No symbol) [0x00D15358]\n\t(No symbol) [0x00CFD293]\n\t(No symbol) [0x00D5E37B]\n\t(No symbol) [0x00D6C473]\n\t(No symbol) [0x00D5A536]\n\t(No symbol) [0x00D382DC]\n\t(No symbol) [0x00D393DD]\n\tGetHandleVerifier [0x010DAABD+2539405]\n\tGetHandleVerifier [0x0111A78F+2800735]\n\tGetHandleVerifier [0x0111456C+2775612]\n\tGetHandleVerifier [0x00F051E0+616112]\n\t(No symbol) [0x00E15F8C]\n\t(No symbol) [0x00E12328]\n\t(No symbol) [0x00E1240B]\n\t(No symbol) [0x00E04FF7]\n\tBaseThreadInitThunk [0x76B27D59+25]\n\tRtlInitializeExceptionChain [0x77AFB74B+107]\n\tRtlClearBits [0x77AFB6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m keyword \u001b[39min\u001b[39;00m keywords:\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstart keyword - \u001b[39m\u001b[39m{\u001b[39;00mkeyword\u001b[39m}\u001b[39;00m\u001b[39m crawling ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     crawl_news_data(keyword\u001b[39m=\u001b[39;49mkeyword, year\u001b[39m=\u001b[39;49m\u001b[39m2022\u001b[39;49m, month\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, start_day\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, end_day\u001b[39m=\u001b[39;49m\u001b[39m13\u001b[39;49m, save_path\u001b[39m=\u001b[39;49msave_path)\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mcrawl_news_data\u001b[1;34m(keyword, year, month, start_day, end_day, save_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m target_date \u001b[39m=\u001b[39m date_time_obj\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m ds_de \u001b[39m=\u001b[39m date_time_obj\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY.\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm.\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m get_naver_news_info_from_selenium(keyword\u001b[39m=\u001b[39;49mkeyword, save_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00msave_path\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mkeyword\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mtarget_date\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mkeyword\u001b[39m}\u001b[39;49;00m\u001b[39m_.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m, target_date\u001b[39m=\u001b[39;49mtarget_date, ds_de\u001b[39m=\u001b[39;49mds_de, remove_duplicate\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[11], line 90\u001b[0m, in \u001b[0;36mget_naver_news_info_from_selenium\u001b[1;34m(keyword, save_path, target_date, ds_de, sort, remove_duplicate)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m more_news_url \u001b[39min\u001b[39;00m more_news_url_list:\n\u001b[0;32m     89\u001b[0m     driver \u001b[39m=\u001b[39m wd\u001b[39m.\u001b[39mChrome(\u001b[39m\"\u001b[39m\u001b[39m../../ssuyan/PAST_NEWS/chromedriver_win32.zip/chromedriver\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m     driver\u001b[39m.\u001b[39;49mget(more_news_url)\n\u001b[0;32m     92\u001b[0m     press_list, title_list, link_list, more_news_url_list \u001b[39m=\u001b[39m get_article_info(driver\u001b[39m=\u001b[39mdriver, \n\u001b[0;32m     93\u001b[0m                                                                      crawl_date\u001b[39m=\u001b[39mcrawl_date, \n\u001b[0;32m     94\u001b[0m                                                                      press_list\u001b[39m=\u001b[39mpress_list, \n\u001b[0;32m     95\u001b[0m                                                                      title_list\u001b[39m=\u001b[39mtitle_list, \n\u001b[0;32m     96\u001b[0m                                                                      link_list\u001b[39m=\u001b[39mlink_list,\n\u001b[0;32m     97\u001b[0m                                                                      date_list\u001b[39m=\u001b[39mdate_list)\n\u001b[0;32m     98\u001b[0m     driver\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:449\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.199)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E7A813+48355]\n\t(No symbol) [0x00E0C4B1]\n\t(No symbol) [0x00D15358]\n\t(No symbol) [0x00CFD293]\n\t(No symbol) [0x00D5E37B]\n\t(No symbol) [0x00D6C473]\n\t(No symbol) [0x00D5A536]\n\t(No symbol) [0x00D382DC]\n\t(No symbol) [0x00D393DD]\n\tGetHandleVerifier [0x010DAABD+2539405]\n\tGetHandleVerifier [0x0111A78F+2800735]\n\tGetHandleVerifier [0x0111456C+2775612]\n\tGetHandleVerifier [0x00F051E0+616112]\n\t(No symbol) [0x00E15F8C]\n\t(No symbol) [0x00E12328]\n\t(No symbol) [0x00E1240B]\n\t(No symbol) [0x00E04FF7]\n\tBaseThreadInitThunk [0x76B27D59+25]\n\tRtlInitializeExceptionChain [0x77AFB74B+107]\n\tRtlClearBits [0x77AFB6CF+191]\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords:\n",
    "    print(f\"start keyword - {keyword} crawling ...\")\n",
    "    crawl_news_data(keyword=keyword, year=2022, month=1, start_day=1, end_day=13, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
