{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4.element\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "conn = pymysql.connect(\n",
    "    host='34.64.240.96'\n",
    "    , user='root'\n",
    "    , password='tndusWkd1.'\n",
    "    , db='final_project'\n",
    "    , charset='utf8'\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  0\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.DataFrame(\n",
    "    data=None,\n",
    "    index=None,\n",
    "    columns=['date','title','link','content']\n",
    ")\n",
    "\n",
    "#중복 행 지우기\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "print(\"중복 제거 후 행 개수: \",len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConnectionError방지\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'}\n",
    "\n",
    "# BeautifulSoup 객체 생성\n",
    "def get_soup_obj(url):\n",
    "    res = requests.get(url, headers = headers, verify=False)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스의 기본 정보 가져오기\n",
    "def get_top3_news_info():\n",
    "    news_urls =[]\n",
    "    \n",
    "    # 해당 분야 상위 뉴스 목록 주소\n",
    "    sec_url = \"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=101\"\n",
    "    \n",
    "    # 해당 분야 상위 뉴스 HTML 가져오기\n",
    "    soup = get_soup_obj(sec_url)\n",
    "  \n",
    "    # 해당 분야 상위 뉴스 3개 가져오기\n",
    "\n",
    "    lis3 = soup.find('ul', class_='type06_headline').find_all(\"li\", limit=3)\n",
    "    for li in lis3:\n",
    "        news_url = li.a.attrs.get('href')\n",
    "        news_urls.append(news_url)\n",
    "\n",
    "    \n",
    "    print(news_urls)\n",
    "    return news_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 3개 뉴스 크롤링\n",
    "def F_crawling(news_urls):\n",
    "    news_titles=[]\n",
    "    news_contents=[]\n",
    "    news_dates=[]\n",
    "\n",
    "    for url in news_urls:\n",
    "        news_html = get_soup_obj(url)\n",
    "\n",
    "\n",
    "        # 뉴스 제목 가져오기\n",
    "        title = news_html.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "        if title == None:\n",
    "            title = news_html.select_one(\"#content > div.end_ct > div > h2\")\n",
    "\n",
    " \n",
    "        # 뉴스 본문 가져오기\n",
    "        content = news_html.select(\"div#dic_area\")\n",
    "        if content == []:\n",
    "            content = news_html.select(\"#articeBody\")\n",
    "            \n",
    "        # 기사 텍스트만 가져오기\n",
    "        # list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        pattern1 = '<[^>]*>'\n",
    "        title = re.sub(pattern=pattern1, repl='', string=str(title))\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "\n",
    "        news_titles.append(title)\n",
    "        news_contents.append(content)\n",
    "\n",
    "        html_date = news_html.select_one(\"div#ct > div.media_end_head > div.media_end_head_info > div span\")\n",
    "        news_date = html_date.attrs['data-date-time']\n",
    "        news_dates.append(news_date)\n",
    "\n",
    "    a = pd.DataFrame({'date':news_dates, 'title':news_titles, 'link':news_urls, 'content':news_contents})\n",
    "\n",
    "    #중복 행 지우기\n",
    "    a = a.drop_duplicates(keep='first',ignore_index=True)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearnews():\n",
    "    special_char = '\\/:*?\"<>|\\''\n",
    "    for clear in special_char:\n",
    "        if clear in title:\n",
    "            print(title.find(clear),clear)\n",
    "            title = title.replace(clear,'')\n",
    "    print(title)\n",
    "\n",
    "def clearnews():\n",
    "    special_char = '\\/:*?\"<>|\\'\\''\n",
    "    for clear in special_char:\n",
    "        if clear in content:\n",
    "            print(content.find(clear),clear)\n",
    "            content = content.replace(clear,'')\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://n.news.naver.com/mnews/article/003/0011957925?sid=101', 'https://n.news.naver.com/mnews/article/009/0005154753?sid=101', 'https://n.news.naver.com/mnews/article/031/0000757038?sid=101']\n",
      "                  date                                      title   \n",
      "0  2023-07-06 14:59:13       경계현 \"삼성 HBM 점유율 여전히 50% 이상\"…시장 우려 일축  \\\n",
      "1  2023-07-06 14:59:05  “해지하러 은행 간다 vs 각서 써주겠다”…새마을금고 앞서 벌어진 설왕설래   \n",
      "2  2023-07-06 14:59:03                  현대백화점그룹, 단일 지주회사 체제 구축 추진   \n",
      "\n",
      "                                                link   \n",
      "0  https://n.news.naver.com/mnews/article/003/001...  \\\n",
      "1  https://n.news.naver.com/mnews/article/009/000...   \n",
      "2  https://n.news.naver.com/mnews/article/031/000...   \n",
      "\n",
      "                                             content  \n",
      "0  [\\n임직원 대상 '위톡'서 밝혀…\"고객사 평가 긍정적\"삼성전자 HBM3·DDR5 ...  \n",
      "1  [\\n\\n\\n\\n\\n 6일 오전 서울 종로구의 한 새마을금고 지점에 관련 안내문이 ...  \n",
      "2  [\\n현대지에프홀딩스, 6일 이사회 열고 현대백화점 현물출자 진행키로현대백화점그룹이...  \n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "news_urls = get_top3_news_info()\n",
    "a = F_crawling(news_urls)\n",
    "news_df=pd.concat([news_df,a])\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "print(news_df.head())\n",
    "\n",
    "# time.sleep(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsDate = news_df['date'].to_list()\n",
    "NewsTItle = news_df['title'].to_list()\n",
    "NewsUrl = news_df['link'].to_list()\n",
    "NewsContent = news_df['content'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES ('2023-07-06 14:59:13', '경계현 \"삼성 HBM 점유율 여전히 50% 이상\"…시장 우려 일축', 'https://n.news.naver.com/mnews/article/003/0011957925?sid=101', '[\n",
      "임직원 대상 '위톡'서 밝혀…\"고객사 평가 긍정적\"삼성전자 HBM3·DDR5 시대에도 '초격차' 지속 다짐\n",
      "\n",
      "\n",
      "\n",
      "[용인=뉴시스] 김종택 기자 = 27일 오후 경기도 용인시 삼성전자 기흥캠퍼스에서 열린 ‘용인 첨단 시스템반도체 국가산단 성공을 위한 제3차 범정부 추진지원단 회의’에서 협약식 후 경계현 삼성전자 대표이사가 발언하고 있다. (공동취재사진) 2023.06.27. photo@newsis.com[서울=뉴시스]이인준 기자 = 경계현 삼성전자 디바이스솔루션(DS) 부문장(사장)이 인공지능(AI) 반도체 시대의 총아인 고대역폭메모리(HBM) 제품 시장에 대한 강한 자신감을 나타냈다.6일 업계에 따르면 경 사장은 전날 사내 소통 채널 '위톡'에서 \"삼성 고대역폭메모리(HBM) 제품의 시장 점유율이 여전히 50% 이상\"이라고 말했다.HBM은 여러 개의 D램을 수직으로 연결해 기존 D램보다 데이터 처리 속도를 끌어올린 제품이다. 데이터 처리량이 급격하게 증가하는 AI용 반도체를 개발하는데 필수적인 요소로 부상하고 있다. 일각에서는 최근 미국 반도체 기업인 엔비디아와 SK하이닉스의 4세대 'HBM3' 협력 강화로 삼성전자의 시장 지배력이 흔들리는 것이 아니냐는 우려가 나오자 경 사장이 나서 일축한 것이다. HBM 시장은 아직 시장 형성 초기 단계로, 전체 D램 시장에서 차지하는 비중은 미미하다. 하지만 AI 개발 열풍 속에서 가파른 성장세를 나타내고 있다. 시장조사업체 트렌드포드에 따르면 전 세계 HBM 수요는 올해 2억9000만 기가바이트(GB)로 작년보다 60% 가까이 증가하고 내년에는 30% 더 성장할 전망이다.삼성전자는 올해 AI 시장의 본격 성장에 발맞춰 고성능 메모리 솔루션 제품군을 강화하고 있다. 삼성전자는 HBM3 16GB(기가바이트)와 12단 24GB 제품 샘플을 출하 중이며 양산 준비를 서두르고 있다. 차세대 HBM D램인 'HBM3P' 제품을 출시 예정이다. 경 사장은 \"최근 (삼성의) HBM3 제품이 고객사들로부터 우수하다는 평가를 받고 있다\"며 \"HBM3와 (하반기 출시 예정인 차세대) HBM3P가 내년에는 DS부문 이익 증가에 기여할 것\"이라고 밝혔다. HBM 외에도 차세대 AI 반도체 솔루션 개발에도 공을 들이고 있다. 삼성전자는 HBM에 연산기를 결합한 메모리 반도체 'HBM-PIM(프로세스 인 메모리)'를 세계 최초로 개발했다. 이어 PIM 기술을 적용한 다양한 제품군을 개발 중이다. D램 모듈에 AI엔진을 장착한 'AXDIMM(Acceleration DIMM)', SSD에 연산기능을 탑재한 스마트 SSD 등이 대표적이다. 또 메모리 확장성이 뛰어난 'CXL(컴퓨트 익스프레스 링크) D램 등도 차세대 인터페이스로 개발 중이다.고성능 메모리에 대한 시장의 수요가 부쩍 높아지면서 고객사 추가 확보에 대한 기대감도 크다. 최근 IT 팁스터(정보유출자) '레베그너스(Revegnus)'에 따르면 AMD가 최근 공개한 AI용 슈퍼칩 MI300에 삼성전자의 HBM3가 적용될 것으로 전해졌다. 또 인텔 오로라 프로젝트와 AMD의 미국 로렌스 리버모어 국립 연구소의 엑사플롭스급 시스템 '엘 캐피탄' 등 슈퍼컴퓨터에도 삼성전자의 HBM 제품이 탑재될 것으로 알려졌다.경 사장은 삼성전자가 1993년 이후 지켜온 '메모리 반도체 세계 1위'를 차세대 D램 규격인 DDR5 시대에도 흔들림 없이 이어갈 것으로 전망했다.그는 \"DDR5도 올해 연말이면 삼성전자의 D램 평균 시장 점유율을 뛰어넘을 것\"이라며 \"연말까지 삼성 D램이 한 단계 더 앞설 수 있는 계기를 마련하고 내년부터는 실행에 나서겠다\"고 밝혔다.\n",
      "]')\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(1064, 'You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \\'위톡\\'서 밝혀…\"고객사 평가 긍정적\"삼성전자 HBM3·DDR5 시...\\' at line 1')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     sql \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mINSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdate\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mtitle\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39murl\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcontent\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(sql)\n\u001b[1;32m----> 4\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(sql)\n\u001b[0;32m      5\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m      6\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sql \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[0;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mserver_status \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m         first_packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()\n\u001b[0;32m   1202\u001b[0m         \u001b[39mif\u001b[39;00m first_packet\u001b[39m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1203\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m     packet\u001b[39m.\u001b[39;49mraise_for_error()\n\u001b[0;32m    773\u001b[0m \u001b[39mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n\u001b[0;32m    220\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39merrno =\u001b[39m\u001b[39m\"\u001b[39m, errno)\n\u001b[1;32m--> 221\u001b[0m err\u001b[39m.\u001b[39;49mraise_mysql_exception(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m errorclass \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     errorclass \u001b[39m=\u001b[39m InternalError \u001b[39mif\u001b[39;00m errno \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m \u001b[39melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (1064, 'You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \\'위톡\\'서 밝혀…\"고객사 평가 긍정적\"삼성전자 HBM3·DDR5 시...\\' at line 1')"
     ]
    }
   ],
   "source": [
    "for date,title,url,content in zip(NewsDate, NewsTItle, NewsUrl, NewsContent):\n",
    "    sql = \"INSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES (%s, %s, %s, %s)\" % (\"'\"+date+\"'\", \"'\"+title+\"'\", \"'\"+url+\"'\", \"'\"+content+\"'\")\n",
    "    print(sql)\n",
    "    cur.execute(sql)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###데이터 프레임으로 만들기###\n",
    "# from datetime import date, timedelta\n",
    "# import pandas as pd\n",
    "\n",
    "# #데이터 프레임 만들기\n",
    "\n",
    "# # list=[]\n",
    "# a = pd.DataFrame({'date':news_dates,'title':news_titles,'link':news_urls,'content':news_contents})\n",
    "\n",
    "# # list.append([news_df,a])\n",
    "\n",
    "# #데이터 프레임 저장\n",
    "# now = datetime.now() \n",
    "# a.to_csv('C:\\\\big16\\\\trading_project\\\\ssuyan\\\\REAL_NEWS\\\\_{}.csv'.format(now.strftime('%Y%m%d_%H%M%S')),encoding='utf-8-sig',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
