{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4.element\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "conn = pymysql.connect(\n",
    "    host='34.64.240.96'\n",
    "    , user='root'\n",
    "    , password='tndusWkd1.'\n",
    "    , db='final_project'\n",
    "    , charset='utf8'\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 행 개수:  0\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.DataFrame(\n",
    "    data=None,\n",
    "    index=None,\n",
    "    columns=['date','title','link','content']\n",
    ")\n",
    "\n",
    "#중복 행 지우기\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "print(\"중복 제거 후 행 개수: \",len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConnectionError방지\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'}\n",
    "\n",
    "# BeautifulSoup 객체 생성\n",
    "def get_soup_obj(url):\n",
    "    res = requests.get(url, headers = headers, verify=False)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스의 기본 정보 가져오기\n",
    "def get_top3_news_info():\n",
    "    news_urls =[]\n",
    "    \n",
    "    # 해당 분야 상위 뉴스 목록 주소\n",
    "    sec_url = \"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=101\"\n",
    "    \n",
    "    # 해당 분야 상위 뉴스 HTML 가져오기\n",
    "    soup = get_soup_obj(sec_url)\n",
    "  \n",
    "    # 해당 분야 상위 뉴스 3개 가져오기\n",
    "\n",
    "    lis3 = soup.find('ul', class_='type06_headline').find_all(\"li\", limit=3)\n",
    "    for li in lis3:\n",
    "        news_url = li.a.attrs.get('href')\n",
    "        news_urls.append(news_url)\n",
    "\n",
    "    \n",
    "    print(news_urls)\n",
    "    return news_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 3개 뉴스 크롤링\n",
    "def F_crawling(news_urls):\n",
    "    news_titles=[]\n",
    "    news_contents=[]\n",
    "    news_dates=[]\n",
    "\n",
    "    for url in news_urls:\n",
    "        news_html = get_soup_obj(url)\n",
    "\n",
    "\n",
    "        # 뉴스 제목 가져오기\n",
    "        title = news_html.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "        if title == None:\n",
    "            title = news_html.select_one(\"#content > div.end_ct > div > h2\")\n",
    "\n",
    " \n",
    "        # 뉴스 본문 가져오기\n",
    "        content = news_html.select(\"div#dic_area\")\n",
    "        if content == []:\n",
    "            content = news_html.select(\"#articeBody\")\n",
    "            \n",
    "        # 기사 텍스트만 가져오기\n",
    "        # list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        pattern1 = '<[^>]*>'\n",
    "        title = re.sub(pattern=pattern1, repl='', string=str(title))\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "\n",
    "        news_titles.append(title)\n",
    "        news_contents.append(content)\n",
    "\n",
    "        html_date = news_html.select_one(\"div#ct > div.media_end_head > div.media_end_head_info > div span\")\n",
    "        news_date = html_date.attrs['data-date-time']\n",
    "        news_dates.append(news_date)\n",
    "\n",
    "    a = pd.DataFrame({'date':news_dates, 'title':news_titles, 'link':news_urls, 'content':news_contents})\n",
    "\n",
    "    #중복 행 지우기\n",
    "    a = a.drop_duplicates(keep='first',ignore_index=True)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clearnews():\n",
    "#     special_char = ' \\/:*?\\\"\\\"<>|\\'\\' '\n",
    "#     for clear in special_char:\n",
    "#         if clear in title:\n",
    "#             print(title.find(clear),clear)\n",
    "#             title = title.replace(clear,'')\n",
    "#     print(title)\n",
    "\n",
    "# def clearnews():\n",
    "#     special_char = ' \\/:*?\\\"\\\"<>|\\'\\' '\n",
    "#     for clear in special_char:\n",
    "#         if clear in content:\n",
    "#             print(content.find(clear),clear)\n",
    "#             content = content.replace(clear,'')\n",
    "#     print(content)\n",
    "\n",
    "def text_clean(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[a-zA-Z0-9]'    # 숫자와 알파벳 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[\\n]'            # \\n제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[\\t]'            # \\n제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://n.news.naver.com/mnews/article/003/0011959788?sid=101', 'https://n.news.naver.com/mnews/article/003/0011959787?sid=101', 'https://n.news.naver.com/mnews/article/119/0002728504?sid=101']\n",
      "                  date                              title   \n",
      "0  2023-07-07 11:47:05  교원 빨간펜, 7월 한달간 '슈퍼위크'…\"할인·사은품 쏜다\"  \\\n",
      "1  2023-07-07 11:47:04                        [인사]중소벤처기업부   \n",
      "2  2023-07-07 11:47:01     킨텍스, 온오프믹스와 함께 \"한국판 유레카파크 만든다\"   \n",
      "\n",
      "                                                link   \n",
      "0  https://n.news.naver.com/mnews/article/003/001...  \\\n",
      "1  https://n.news.naver.com/mnews/article/003/001...   \n",
      "2  https://n.news.naver.com/mnews/article/119/000...   \n",
      "\n",
      "                                             content  \n",
      "0  [\\n\\n\\n\\n\\n[서울=뉴시스] 교원 빨간펜 '슈퍼위크'. (이미지=교원 제공)...  \n",
      "1  [\\n\\t\\t\\t[서울=뉴시스] ◇과장급 전보▲비상재난담당관 채왕식▶ 네이버에서 뉴...  \n",
      "2  [\\n스타트업 네트워킹과 이벤트플랫폼 활용..스타트업 참여기회 확대\\n\\n\\n\\n양...  \n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "news_urls = get_top3_news_info()\n",
    "a = F_crawling(news_urls)\n",
    "news_df=pd.concat([news_df,a])\n",
    "news_df = news_df.drop_duplicates(keep='first',ignore_index=True)\n",
    "print(news_df.head())\n",
    "\n",
    "# time.sleep(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsDates = news_df['date'].to_list()\n",
    "NewsTItles = news_df['title'].to_list()\n",
    "NewsUrls = news_df['link'].to_list()\n",
    "NewsContents = news_df['content'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES ('2023-07-07 11:47:05', '교원 빨간펜, 7월 한달간 '슈퍼위크'…\"할인·사은품 쏜다\"', 'https://n.news.naver.com/mnews/article/003/0011959788?sid=101', '[\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[서울=뉴시스] 교원 빨간펜 '슈퍼위크'. (이미지=교원 제공) 2023.07.07. photo@newsis.com[서울=뉴시스] 배민욱 기자 = 교원 빨간펜이 여름방학을 맞아 7월 한달간 할인 이벤트를 진행한다.7일 교원에 따르면 빨간펜 슈퍼위크 이벤트는 기존·신규 고객을 대상으로 전집, 아이캔두 상품을 할인해 선보인다. 교원 빨간펜은 10일까지 전집을 구매하는 고객을 대상으로 전집 전 품목을 10% 할인된 가격에 제공한다. 또 전집을 묶음 구매하는 고객에게는 어린이용 독서대와 독서등을 증정한다.13일까지 아이캔두를 구매하는 전 고객은 10% 할인 혜택을 받는다. 교원 빨간펜은 ▲아이캔두 초등 ▲솔루토이 국어 ▲솔루토이 한자로 구성된 독서 패키지 구매 시 '국어의 정석'을 특별 사은품으로 제공한다.7월 한달간 아이캔두와 도요새를 신규로 가입하는 고객은 신규 패드 렌탈 시 렌탈료 50% 할인, 리퍼 패드 2년 무상 렌탈, 패드 구매 시 20만원 할인 혜택을 얻는다.\n",
      "]')\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(1064, 'You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \\'슈퍼위크\\'…\"할인·사은품 쏜다\"\\', \\'https://n.news.naver.com/mnews/...\\' at line 1')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     sql \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mINSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdate\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mtitle\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39murl\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcontent\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(sql)\n\u001b[1;32m----> 4\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(sql)\n\u001b[0;32m      5\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m      6\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sql \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[0;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mserver_status \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m         first_packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()\n\u001b[0;32m   1202\u001b[0m         \u001b[39mif\u001b[39;00m first_packet\u001b[39m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1203\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m     packet\u001b[39m.\u001b[39;49mraise_for_error()\n\u001b[0;32m    773\u001b[0m \u001b[39mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n\u001b[0;32m    220\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39merrno =\u001b[39m\u001b[39m\"\u001b[39m, errno)\n\u001b[1;32m--> 221\u001b[0m err\u001b[39m.\u001b[39;49mraise_mysql_exception(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
      "File \u001b[1;32mc:\\Users\\green\\anaconda3\\envs\\pandas-dev\\lib\\site-packages\\pymysql\\err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m errorclass \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     errorclass \u001b[39m=\u001b[39m InternalError \u001b[39mif\u001b[39;00m errno \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m \u001b[39melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (1064, 'You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \\'슈퍼위크\\'…\"할인·사은품 쏜다\"\\', \\'https://n.news.naver.com/mnews/...\\' at line 1')"
     ]
    }
   ],
   "source": [
    "for date,title,url,content in zip(NewsDates, NewsTItles, NewsUrls, NewsContents):\n",
    "    sql = \"INSERT INTO real_news (NewsDates,NewsTitles,NewsUrls,NewsContents) VALUES (%s, %s, %s, %s)\" % (\"'\"+date+\"'\", \"'\"+title+\"'\", \"'\"+url+\"'\", \"'\"+content+\"'\")\n",
    "    print(sql)\n",
    "    cur.execute(sql)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###데이터 프레임으로 만들기###\n",
    "# from datetime import date, timedelta\n",
    "# import pandas as pd\n",
    "\n",
    "# #데이터 프레임 만들기\n",
    "\n",
    "# # list=[]\n",
    "# a = pd.DataFrame({'date':news_dates,'title':news_titles,'link':news_urls,'content':news_contents})\n",
    "\n",
    "# # list.append([news_df,a])\n",
    "\n",
    "# #데이터 프레임 저장\n",
    "# now = datetime.now() \n",
    "# a.to_csv('C:\\\\big16\\\\trading_project\\\\ssuyan\\\\REAL_NEWS\\\\_{}.csv'.format(now.strftime('%Y%m%d_%H%M%S')),encoding='utf-8-sig',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
